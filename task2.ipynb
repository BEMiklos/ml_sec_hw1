{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "import torch.nn as nn\n",
    "from typing import Tuple\n",
    "from torchvision.datasets import DatasetFolder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(1, 16, kernel_size=(10,), stride=(1,))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        self.linear = nn.Linear(65496, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pooling(self.relu(self.conv(x)))\n",
    "        x = x.view(-1, 65496) # flatten\n",
    "        x = self.sigmoid(self.linear(x))\n",
    "        return x.reshape(-1) # keep only the batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv): Conv1d(1, 16, kernel_size=(10,), stride=(1,))\n",
       "  (relu): ReLU()\n",
       "  (pooling): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (linear): Linear(in_features=65496, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ConvNet().to(device)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining transform with mask and sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform updated to create he mask along the input tensor\n",
    "class BinaryTransformWithMask:\n",
    "    def __init__(self, input_length: int, adversarial_ratio: float) -> None:\n",
    "        \"\"\"Initializes the length and ratio parameter that defines this transform.\"\"\"\n",
    "        self.input_length = input_length\n",
    "        self.adversarial_ratio = adversarial_ratio\n",
    "\n",
    "    def __call__(self, binary_data: bytes) -> Tuple[torch.Tensor, np.array]:\n",
    "        \"\"\"Returns the model input prepared as a (1,input_length) Tensor,\n",
    "        and the mask which indicates positions influenced exclusively by the adv. suffix.\n",
    "        as a NumPy array.\"\"\"\n",
    "\n",
    "        l_original = len(binary_data)\n",
    "        binary_array = self.get_extended_binary_array(binary_data)\n",
    "        l_with_adversarial = len(binary_array)\n",
    "\n",
    "        if l_with_adversarial < self.input_length:\n",
    "            # the bytes array is too short and zero padding should be added to match input_length\n",
    "            # the mask does not include the zero-padding bytes\n",
    "            padding = np.zeros(self.input_length - l_with_adversarial, dtype=np.uint8)\n",
    "            binary_array = np.concatenate((binary_array, padding))\n",
    "            mask = np.arange(l_original, l_with_adversarial)\n",
    "        elif l_with_adversarial > self.input_length:\n",
    "            # the byte array should be split into ceil(l_with_adversarial / input_length) chunks,\n",
    "            # with the last chunk being padded to chunk size if needed\n",
    "            # the chunks where there are padding 0s present are not part of the mask,\n",
    "            # as they are not influenced only by the adversarial bytes.\n",
    "            window_size = ceil(l_with_adversarial / self.input_length)\n",
    "            # byte groups influenced by the original binary:\n",
    "            num_original_groups = ceil(l_original / window_size)\n",
    "            l_padding = self.input_length * window_size - l_with_adversarial\n",
    "            # byte groups influenced by the automatic padding:\n",
    "            num_padding_groups = ceil(l_padding / window_size)\n",
    "            padding = np.zeros(l_padding, dtype=np.uint8)\n",
    "            binary_array = np.concatenate((binary_array, padding))\n",
    "            binary_array = binary_array.reshape(-1, window_size)\n",
    "            binary_array = np.mean(binary_array, axis=1)\n",
    "            mask = np.arange(num_original_groups, self.input_length - num_padding_groups)\n",
    "        else:\n",
    "            # no padding needed, mask is straightforward\n",
    "            mask = np.arange(l_original, l_with_adversarial)\n",
    "            \n",
    "        # Scale the data to [0, 1]\n",
    "        scaled_data = binary_array / 255.0\n",
    "        tensor = torch.tensor(scaled_data, dtype=torch.float32)\n",
    "        # Add extra dimension for the model to work properly.\n",
    "        return tensor.unsqueeze(0), mask\n",
    "\n",
    "    def get_extended_binary_array(self, binary_data: bytes) -> np.array:\n",
    "        \"\"\"Build the extended binary with the adversarial suffix set to zero.\"\"\"\n",
    "        l = len(binary_data)\n",
    "        l_with_adversarial = ceil(l * (1 + self.adversarial_ratio))\n",
    "        binary_array = np.zeros(l_with_adversarial, dtype=np.uint8)\n",
    "        binary_array[:l] = np.frombuffer(binary_data, dtype=np.uint8)\n",
    "        return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0078, 0.0196, 0.0314, 0.0131, 0.0000, 0.0000]]),\n",
       " array([], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example #1 in the assignment text (sanity check)\n",
    "binary_data = bytes(list(range(1, 11)))\n",
    "transform = BinaryTransformWithMask(input_length=6, adversarial_ratio=0.4) # +4 bytes\n",
    "X, M = transform(binary_data)\n",
    "X, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.0078, 0.0196, 0.0314, 0.0131, 0.0000, 0.0000]]), array([4]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example #2 in the assignment text (sanity check)\n",
    "binary_data = bytes(list(range(1, 11)))\n",
    "transform = BinaryTransformWithMask(input_length=6, adversarial_ratio=0.5) # +5 bytes\n",
    "X, M = transform(binary_data)\n",
    "X, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proof of concept preprocessing pipeline applied on a single sample in the victim folder\n",
    "file_path = \"data/victim/malware/0d41d1d904aecf716303f55108e020fbd9a4dbcd997efb08fba5e10e936d419c\"\n",
    "with open(file_path, \"rb\") as f:\n",
    "    binary_data = f.read()\n",
    "\n",
    "transform = BinaryTransformWithMask(input_length=2**14, adversarial_ratio=0.1)\n",
    "input_tensor, M = transform(binary_data)\n",
    "input_tensor = input_tensor.unsqueeze(0) # add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1450, array([14505, 14506, 14507, ..., 15952, 15953, 15954]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M), M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9596], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline confidence in the sample's malware-ness\n",
    "model(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random adversary suffix for baseline attack (one sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7d57fbea2f30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9701], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observing the effect of the random bytes with an adversarial ratio of 10% (mask length: 1450)\n",
    "input_with_adversary = input_tensor.clone()\n",
    "adversary_features = torch.rand(len(M), dtype=torch.float32)\n",
    "input_with_adversary[...,M] += adversary_features\n",
    "model(input_with_adversary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized attack with PGD (one sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0: -0.03119338\n",
      "Epoch: 5: -0.06751740\n",
      "Epoch: 10: -0.13005204\n",
      "Epoch: 15: -0.22691730\n",
      "Epoch: 20: -0.36139640\n",
      "Epoch: 25: -0.53739083\n",
      "Epoch: 30: -0.74266338\n",
      "Epoch: 35: -0.96414167\n",
      "Epoch: 40: -1.19166565\n",
      "Epoch: 45: -1.40630639\n"
     ]
    }
   ],
   "source": [
    "# Untargeted PGD attack\n",
    "adversary_features = torch.rand(len(M), dtype=torch.float32, requires_grad=True)\n",
    "# the value of eps. is provided here: 0.01 found as an optimal value through trial-and-error\n",
    "opt = torch.optim.SGD([adversary_features], lr=0.01)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "for t in range(50):\n",
    "    # We apply the masked bytes as an additive, bounded noise over the 0s in the input_tensor's mask positions\n",
    "    input_with_adversary = input_tensor.clone()\n",
    "    input_with_adversary[...,M] += adversary_features\n",
    "    pred = model(input_with_adversary).squeeze()\n",
    "    loss = -loss_fn(pred, torch.tensor(1, dtype=torch.float32)) # 1 = malware\n",
    "    if t % 5 == 0:\n",
    "        print(f\"Epoch: {t}: {loss.detach().item():.8f}\")\n",
    "       \n",
    "    opt.zero_grad()\n",
    "    loss.backward()\n",
    "    # use the sign method for the gradients\n",
    "    adversary_features.grad.sign_()\n",
    "    opt.step()\n",
    "\n",
    "    # projection with clipping\n",
    "    adversary_features.data.clamp_(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2087], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observing the effect of the PGD attack on the model's output - way more significant\n",
    "model(input_with_adversary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 0.0000, 0.2817,  ..., 1.0000, 1.0000, 0.9841],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversary_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preformance of random adversarial attack with 5%, 10%, 15%, 20% adversarial bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy of random adversarial bytes based on adversarial-to-original byte count ratio.\n",
      "Ratio\tACC.\tMean. |M|\n",
      "0.05:\t0.0000\t690.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1:\t0.0000\t1340.76\n",
      "0.15:\t0.0200\t1937.20\n",
      "0.2:\t0.0000\t2476.10\n"
     ]
    }
   ],
   "source": [
    "print(\"Adversarial accuracy of random adversarial bytes based on adversarial-to-original byte count ratio.\")\n",
    "# We also track mean mask length.\n",
    "print(\"Ratio\\tACC.\\tMean. |M|\")\n",
    "for adversarial_ratio in [0.05, 0.1, 0.15, 0.2]:\n",
    "    # The transform and the dataset are influenced by the adversarial_ratio, so we initialize them here\n",
    "    transform = BinaryTransformWithMask(input_length=2**14, adversarial_ratio=adversarial_ratio)\n",
    "    victim_dataset = DatasetFolder(root=\"data/victim\", loader=lambda x: open(x, 'rb').read(), extensions=('',), transform=transform)\n",
    "    \n",
    "    # accumulating values across the victim dataset\n",
    "    num_successful = 0\n",
    "    mask_len_total = 0\n",
    "    num_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (X, M), y in victim_dataset:\n",
    "            if victim_dataset.classes[y] == \"benign\":\n",
    "                # we only need to attack malware samples\n",
    "                continue\n",
    "            # apply random noise in an additive fashion\n",
    "            input_with_adversary = X.clone()\n",
    "            adversary_features = torch.rand(len(M), dtype=torch.float32)\n",
    "            input_with_adversary[...,M] += adversary_features\n",
    "            # evaluating effect\n",
    "            y_pred = model(input_with_adversary.unsqueeze(0)).squeeze()\n",
    "            pred_label = y_pred > 0.5\n",
    "            if pred_label != y:\n",
    "                num_successful += 1\n",
    "            num_total += 1\n",
    "            mask_len_total += len(M)\n",
    "\n",
    "    print(f\"{adversarial_ratio}:\\t{num_successful / num_total:.4f}\\t{mask_len_total / num_total:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preformance of PGD adversarial attack with 5%, 10%, 15%, 20% adversarial bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adversarial accuracy of PGD based on adversarial-to-original byte count ratio.\n",
      "Ratio\tACC.\tMean. |M|\n",
      "0.05:\t0.2200\t690.04\n",
      "0.1:\t0.5600\t1340.76\n",
      "0.15:\t0.7400\t1937.20\n",
      "0.2:\t0.7600\t2476.10\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "print(\"Adversarial accuracy of PGD based on adversarial-to-original byte count ratio.\")\n",
    "print(\"Ratio\\tACC.\\tMean. |M|\")\n",
    "\n",
    "for adversarial_ratio in [0.05, 0.1, 0.15, 0.2]:\n",
    "    # The transform and the dataset are influenced by the adversarial_ratio, so we initialize them here\n",
    "    transform = BinaryTransformWithMask(input_length=2**14, adversarial_ratio=adversarial_ratio)\n",
    "    victim_dataset = DatasetFolder(root=\"data/victim\", loader=lambda x: open(x, 'rb').read(), extensions=('',), transform=transform)\n",
    "    \n",
    "    num_successful = 0\n",
    "    mask_len_total = 0\n",
    "    num_total = 0\n",
    "\n",
    "    for (X, M), y in victim_dataset:\n",
    "        if victim_dataset.classes[y] == \"benign\":\n",
    "            # we only need to attack malware samples\n",
    "            continue\n",
    "\n",
    "        malware_idx = victim_dataset.class_to_idx[\"malware\"]\n",
    "        \n",
    "        # Optimization is separate for each sample, so we initialize the requires_grad parameters and the optimizer here\n",
    "        adversary_features = torch.rand(len(M), dtype=torch.float32, requires_grad=True)\n",
    "        opt = torch.optim.SGD([adversary_features], lr=0.01)\n",
    "\n",
    "        # PGD\n",
    "        for t in range(100):\n",
    "            input_with_adversary = X.clone().unsqueeze(0) # add batch dimension\n",
    "            input_with_adversary[...,M] += adversary_features\n",
    "            pred = model(input_with_adversary).squeeze()\n",
    "            # untargeted = maximizing loss\n",
    "            loss = -loss_fn(pred, torch.tensor(malware_idx, dtype=torch.float32))\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            adversary_features.grad.sign_()\n",
    "            opt.step()\n",
    "\n",
    "            # projection with clipping\n",
    "            adversary_features.data.clamp_(0, 1)\n",
    "\n",
    "        # Final prediction:\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(input_with_adversary).squeeze()\n",
    "            pred_label = y_pred > 0.5\n",
    "            if pred_label != y:\n",
    "                num_successful += 1\n",
    "            num_total += 1\n",
    "            mask_len_total += len(M)\n",
    "\n",
    "    print(f\"{adversarial_ratio}:\\t{num_successful / num_total:.4f}\\t{mask_len_total / num_total:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
